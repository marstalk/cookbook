# 算法目录
1. tree
2. linkedlist
3. array
4. custom_structure
5. backtracing
6. graph
7. bfs
8. dynamic_programming(dp)
9. skip_list
10. consistent_hashing
11. random
12. virus_dectection
13. majiang
14. stack
15. queue
16. recursion
17. sort
18. bit
19. factorial


# 时间复杂度
1. 常量级别 O(1)
2. 对数 O(logN)：log3^N 或者log4^N都是log2^N，因为都可以转为C*log2^N
3. 线性 O(N)
4. 线性对数 O(NlogN)
5. 平方、立方、n次方 O(N^2), O(N^3)
6. 指数 O(2^N)
7. 阶乘 0(N!)

分析方法：
- 加法法则：多个非嵌套循环，则将多个循环复杂度加起来即可。
- 乘法法则：多个嵌套循环，每一层的时间复杂度相乘即可。

还有一些额外的：
- 最好、最坏时间复杂度。
- 平均时间复杂度
- 均摊时间复杂度（难点）



# ====Structure====

# Array
[code](3.array.algm.md)
数组的几个特性：
1. 线性：只有前后两个方向的元素，线性的数据结构除了数组还有：**链表、队列、栈**；非线性结构有**图、树**等。
2. 存储相同数据类型的数据，使得`data_type_size`是相等的。
3. 使用连续的内存空间，配合第2个特性，可以快速根据起始地址和偏移量（下标）快速找到第N个元素：比如第0个是 `start + 0 * data_type_size`，即**随机访问**的能力(根据下标实现O(1)的时间复杂度查询能力)，Java中使用RandomAccess接口来表示该能力。
4. 低效的插入和删除。
5. 在特殊情况下对插入和删除的优化。比如在i插入元素，只需要将当前i的元素放置到末尾即可（快排思想起源）；删除可以做**删除标记**，等空间不足之后再**物理删除**。


为什么大部分的程序语言的数组都是从0开始？而不是1呢？毕竟1更加符合人类的思维习惯。
1. 底层计算机寻址指令可以少计算一个减法：数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。
2. 历史原因：C 语言设计者用 0 开始计数数组下标，之后的 Java、JavaScript 等高级语言都效仿了 C 语言，或者说，为了在一定程度上减少 C 语言程序员学习 Java 的学习成本，因此继续沿用了从 0 开始计数的习惯。实际上，很多语言中数组也并不是从 0 开始计数的，比如 Matlab。甚至还有一些语言支持负数下标，比如 Python。

多维数组的寻址空间公式推论：
```
1. 一维a: arr[i] = base + i * unit
2. 二维a*b: arr[i][j] = base + i*b*unit + j*unit                 = base + (i*b + j)*unit
3. 三维a*b*c: arr[i][j][k] = base + i*b*unit + j*c*unit + k*unit = base + (i*b + j*c + k)*unit
4. N维a*b*c...: arr[i]... =                                      = base + (i*b + j*c + ...)*unit
```

# LinkedList
[code](2.linkedlist.algm.md)

# Stack
[here](14.stack.algm.md)
这是一个【操作受限】的数据结构，有两种实现方式：数组（顺序栈）和链表（链式栈）。Java中的Stack是顺序栈（初始容量是10）

🌶数组实现的栈在扩容的时候,均摊时间复杂度是O(1)

# Queue
[here](15.queue.algm.md)
同样是一个【操作受限】的线性数据结构，有两种实现方式：数组（顺序队列）和链表（链式队列），具有额外特性的队列：
1. 循环队列
2. 阻塞队列
3. 并发队列


# Recursion


# DHT
Distributed Hash Table，分布式哈希表，适用于分布式系统拥有大量节点，并且节点经常加入并离开集群的场景。

# Skip-List
本质：**链表** → **有序链表** → **多级有序链表**：可以进行二分查找的有序链表。

对比红黑树、AVL树来说，效率差不多，但是实现简单！这两棵树虽然查找效率高log（N），但是在构建数据结果的时候，好复杂啊。跳表就是使用简单的数据结构（链表）来实现近似log(N)的查询效率。

随机化怎么体现。

论文：[skip.pdf](https://homepage.divms.uiowa.edu/~ghosh/skip.pdf)




# Heap
一个数组，堆逻辑上是一个满二叉树，满二叉树是节点数=2的深度+1次方只和或者从左到右是满的。

使用堆来实现优先队列，排序等
`PriorityQueue<Integer> p = new PriorityQueue();`

时间复杂度把扩容考虑进去，也是logN：N个元素，从2，4，8，16...N，需要扩容logN次，每次扩容的需要拷贝N个元素，那么总的时间复杂度是O(N * log N)

但是个黑盒有个缺点：只支持元素的增加和弹出，不支持元素的修改，修改之后，它需要从头扫描做heapify或者insert操作，代价比较大。相比较之下，我们自己写的堆，可以从特定位置出来做heapify。

在面试中，如果只是简单的使用add和poll方法，那么我们可以直接使用priorityQueue，而如果需要做一个其他操作，我们需要自己手写一个堆。这个很重要‼️ TODO

# Hash
一个函数，将任何长度的字符串经过一定的计算之后得到固定长度的数字，该数字习惯性使用16进制表示

这里有几点：
- 既然是函数，那么一个输入x，总是能够得到固定对应不变的输出y。
- 输出是固定长度的，这个长度不同的哈希实现有不同的长度，不做硬性规定。
- 输入是任意长度的，既可以是一个字符，也可以一篇文章（归根结底是01二进制文件）
- 不可能通过输出反推出输入，即无法解密 。【无法解密】【不可逆】

**安全的哈希算法** 

并不是所有的哈希算法都是安全的，或者说要成为安全的哈希函数，还要有额外的条件：
- 碰撞概率极低，假设固定输出长度是2，那么这个碰撞的概率实在是太大了。
- 无法猜测输出，既输入即使只有小小的改动，比如三国小说的标点符号做小小的改动，也会输出完全不一样的哈希值，即相似的输入不会输出相似的哈希。

输出长度越长，碰撞的概率越低，越安全。

**希算法用途**

1. 防止篡改，比如在官方下载的页面，经常会给出下载包的一个摘要，比如MD5摘要，当我们下载软件之后，对软件包进行MD5摘要计算，如果两个值不相等，那么就说明下载的这个软件被篡改了。
2. 存储口令，比如数据库存储用户的密码，肯定是不能明文存储的，我们可以通过存储哈希值的方式来记住用户的口令摘要，当用户登陆的时候，只需要对比摘要是否一致即可，这个场景就要求碰撞的的概率要极低！
    1. 上述方案，仍然需要用户使用复杂度较高的密码，否则通过彩虹表，仍可以快速找到密码原文。
    2. 退一万步来说，用户真的使用了常见密码怎么办？我们可以对原文+随机字符串（盐）的方式来使得彩虹表失效。hash(bob + "H1r0a")

|username|salt|password|
|-|-|-|
|bob|H1r0a|a5022319ff4c56955e22a74abcc2c210|
|alice|7$p2w|e5de688c99e961ed6e560b972dab8b6a|
|tim|z5Sk9|1eee304b92dc0d105904e7ab58fd2f64|


```Java
import java.math.BigInteger;
import java.security.MessageDigest;

public class Main {
    public static void main(String[] args) throws Exception {
        // 创建一个MessageDigest实例，参数或者MD5或者SHA-256等
        MessageDigest md = MessageDigest.getInstance("MD5");
        // 反复调用update输入数据:
        md.update("Hello".getBytes("UTF-8"));
        md.update("World".getBytes("UTF-8"));
        byte[] result = md.digest(); // 16 bytes: 68e109f0f40ca72a15e05cc22786f8e6
        System.out.println(new BigInteger(1, result).toString(16));
    }
}

```


常见的哈希实现有：
|算法|输出长度（位）|输出长度（字节）|是否推荐使用|
|-|-|-|-|
|MD5（Message Digest 5）|128 bits|16 bytes|否|
|SHA（Security Hash Algorithm）-1|160 bits|20 bytes|否|
|RipeMD-160|160 bits|20 bytes||
|SHA-256|256 bits|32 bytes||
|SHA-512|512 bits|64 bytes|是|
|murmurHash|128 or 32 | 16bytes or 4bytes| 极力推荐，性能是MD5的十倍|

**哈希实现之MurmurHash**

```xml
<!-- https://mvnrepository.com/artifact/com.google.guava/guava -->
<dependency>
    <groupId>com.google.guava</groupId>
    <artifactId>guava</artifactId>
    <version>31.1-jre</version>
</dependency>

```
Google出品的Hash包


**哈希实现之MD5**

# RingBuffer

JDK提供的的线程安全的队列：
- ArrayBlockingQueue 是 数组array ReentrantLock 有锁 有界
- LinkedBlockingQueue 是 链表 ReentrantLock 有锁 有界
- LinkedTransferQueue 否 链表 CAS 无锁 无界
- DelayQueue 否 堆Heap CAS 无锁 无界

有界的队列是带锁的，无界的队列才是乐观锁设计。但是实际情况下，使用无界队列对我们的系统始终是一个隐患（毕竟没有谁家的内存资源是无限大的）。所以我们绝大部分的选择都是ArrayBlockingQueue和LinkedBlockingQueue，这两个使用了ReentrantLock来实现多线程安全。
- ArrayBlokcingQueue offer的时候需要对putIndex++，并赋值操作上锁，保证原子。
- LinkeBlockingQueueu offer的时候的两步：last.next=node; last = last.next;需要上锁，保证原子。

上述两个Queue不管offer或者poll都会使用同一个ReentrantLock进行上锁，即使是单线程写、单线程读的使用场景，在极端情况下，线程还是要进行Park()操作。

对比之下RingBuffer是优化了在单线程读、单线程写的使用场景下的性能，使用CAS无锁设计。**注意，RingBuffer只有在单线程读、单线程写的场景下才是线程安全的**TODO洋哥实现的RingBuffer如何实现多线程读的情况下线程安全？牺牲性能？

# 时间轮 TODO

# MVCC TODO


## 性能
在有界队列中：RingBuffer > ArrayBlockingQueue(ABQ) > LinkedBlockingQueue

## 简单实现
注意：
1. writeSequence初始值是-1，readSequence初始值是0.
2. writeSequence++之后再写；readSequence读了之后再进行++
3. 使用场景限制：
   - 单线程写、单线程读。
   - 无法扩容。

```java
private volatile int writeSequence = -1, readSequence = 0;

public CircularBuffer(int capacity) {
    this.capacity = (capacity < 1) ? DEFAULT_CAPACITY : capacity;
    this.data = (E[]) new Object[this.capacity];
    this.readSequence = 0;
    this.writeSequence = -1;
}

public boolean offer(E element) {
    boolean isFull = (writeSequence - readSequence) + 1 == capacity;
    if (!isFull) {
        int nextWriteSeq = writeSequence + 1;
        // 可以使用位运算来优化寻址速度
        data[nextWriteSeq % capacity] = element;
        writeSequence++;
        return true;
    }
    return false;
}

public E poll() {
    boolean isEmpty = writeSequence < readSequence;
    if (!isEmpty) {
        E nextValue = data[readSequence % capacity];
        readSequence++;
        return nextValue;
    }
    return null;
}

```
## 参考
- [Implementing a Ring Buffer in Java](https://www.baeldung.com/java-ring-buffer#producer-consumer)
- Ringbuffer在Disruptor中的使用。



# LSM-Tree
LSM树-Log-Structure-Merge-Tree
[LSM树详解 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/181498475)

[深入浅出分析LSM树（日志结构合并树） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/415799237)

![picture 1](../../images/b0d0a805de4bcd01d89828e288395a347ff5901362fe0f743ab4884dd545861b.png)  

ES、HBase、LevelDB、Prometheus等都在使用这种结果来实现高速写入。

![picture 2](../../images/448041cde8b0fb1338e1df0eada30f3fbf466aa8af8f573d5fe87b38a821e5cc.png)  

这个并不是一种传统意义上的数据结构，而是一种横跨内存、磁盘的一段算法和结构的结合，我想名字应该叫做**日志结构合并森林**而不是**日志结构合并树**。

内存中，有排序树，保证在搜索以及将内存中的数据写入磁盘的时候都可以进行快速的操作；假设这个有序数是二叉搜索树，那么插入的复杂度是O(logN)，那么查找的复杂度是O(logN)，将整棵树顺序写入磁盘的复杂度是O(N)。

在磁盘中，有两种类型的持久化文件：1）WAL（write ahead logging）生命周期跟内存中的level0保持一致；2）Level1~LevelN多个级别（按照文件大小来分级。也可以说是按照merge的次数来分级，因为一般是文件大小阈值之后进行合并）的内容有序文件集合。

那么涉及到的数据结构与算法可能有：

1. 排序树（二叉搜索树、AVL树等）
2. 归并排序（merge的过程就是一次归并过程）
3. 布隆过滤器，当我们在磁盘上查找key的时候，如果单个文件特别大，虽然可以使用二分查找的方式达到logN的复杂度，但是如果使用布隆过滤器，可以达到更快的效果。

# Redis中的数据结构
http://zhangtielei.com/posts/blog-redis-quicklist.html
## QuickList = array + linkedList
这是Redis中的数据结构，将数组和链表的有点结合起来。Redis暴露给用户的List类型，内部使通过quickList实现的。


# ====Algorithm====

# 排列组合公式
```
C(n,k) = n! / (n-k)!
A(n,k) = P(n,k) = n! / (k!(n-k)!)
```


# 对称-非对称加密解密
## 对称（共享秘钥机密）

加密和机密使用同一个秘钥。常见有AES，DES，动态口令，凯撒密码。



## 非对称（公开密钥加密）

**公钥加密，私钥解密，即防窃听**

公钥解密，私钥解密，只有私钥拥有者和消息发送者才知道明文是什么。常见RSA（02年图领奖）。

所有的用户都可以使用一个公钥，接受者使用一把私钥即可完成接送多人的消息。而在对称加密中，接受者必须维护每个发送者对应的密码，随着发送者越来多，需要管理的秘钥越来越多。

中间人攻击问题，假设：
- A：发送者
- B：接受者
- X：中间人

A通过网络获取B的公钥的时候，被X截取了，X返回给A的是X的公钥。**A无法判断这个公钥是不是B的**。

A使用X的公钥进行数据加密，发送给B，被X截取，X使用秘钥进行解密，获得明文，【**窃听成功**】。

X使用B的公钥，修改A的消息，发送给B，发生了【**篡改**】。

上述问题的核心，就是A无法确定收到的公钥是不是B的。

想要解决这个问题，就需要【**数字证书**】。

加密和解密比较耗时，有20%的性能消耗，比如ES开启TLS和HTTPS之后，性能有20%的性能损耗。

- 可以使用某个数值对数据进行加密
- 使用另外一个数值对加密数据进行计算可以让数据恢复原样。
- 无法从一个秘钥推算出另一种秘钥。

这就是非对称算法的牛逼之处。

## 混合加密

因为数据使用公钥加密较慢，使用私钥解密也较慢，于是使用混合加密的方式来解决效率和安全问题。

A使用对称机密对数据进行加密，然后使用B的公钥对秘钥进行加密。

加密数据和进行非对称加密的秘钥都发送给B

B首先使用私钥解密等到秘钥，然后使用秘钥对数据进行解密，等到明文。

混合加密是SSL/TLS协议的工作原理。

注意，**混合加密并没有解决中间人攻击问题**。

## 数字签名

常用实现是RSA数字签名，用到RSA算法和哈希算法（不可逆）。

**私钥机密，公钥解密，即签名**，证明你是你，防止事后否认问题。

一般是使用RSA非对称加密来实现，因为RSA有一个性质：能够用A的公钥进行解密的密文，必定是由A生成的。

A的一堆参数进行字符串拼接，执行MD5哈希，然后使用秘钥进行加密生成签名字段，一并发送给B

B在接收到参数后，按照同样的规则进行MD5哈希，然后使用提前获取到的A的公钥（比如在接入支付宝支付的时候，在支付宝官方申请公钥）对签名进行解密，如果

```JSON
# A发送的请求，比如支付场景下回调请求。
{
  "orderId": "xxx",
  "transactionId": "yyyy",
  "status": "success",
  "sign": "KDLFJO34Fw43i&%90" # 这个签名是通过 RSA(MD5(orderId + transactionId + status), privateKey)得到
}

```

```java
# B如何验证这个消息的发送者是支付宝，而不是其他中间人呢？
some_hashValue = MD5(orderId + transactionid + status)
# publicKey是在支付宝网站上下载的。
other_hashValue = RSA(sign, publicKey)
if some_hashValue == other_hashValue:
    sender is 支付宝。
```
![picture 4](../../images/00ad1ab6da752d732a821733ed47ec2d966765e325599174f3212fb6a5180528.png)  

手机或者电脑上有CA根证书，根证书上记载了可以信赖的CA机构及其公钥。使用这个就可以用来证明阿里巴巴在网络上的证书是不是真的。
![picture 5](../../images/88860e2c65c0adb50776e85d08b79f9a9ff9048a547d4b5f6a2d43674aa0ccef.png)  



数字证书：证明这个公钥是某人的，即公钥和域名的对应关系。

比如支付宝将公钥和身份信息（www.zhifubao.com）提交给某个签发机构（CA），CA生成一个证书，该证书包含公钥和身份信息。既证明该公钥的生成者是支付宝。
![picture 6](../../images/e4306c8fe534b9561163a3de0a5012405dfea2e02c4f924f4bda081f220b6adc.png)  


如何确定证书不会被伪造呢？

CA机构要对数字证书进行签名


# 计时攻击
当我们使用下面方法判断字符创是否相等时，有一个漏洞：
```java
public boolean equals(Object anObject) {
        if (this == anObject) {
            return true;
        }
        if (anObject instanceof String) {
            String anotherString = (String)anObject;
            int n = value.length;
            if (n == anotherString.value.length) {
                char v1[] = value;
                char v2[] = anotherString.value;
                int i = 0;
                while (n-- != 0) {
                    if (v1[i] != v2[i])
                        return false;
                    i++;
                }
                return true;
            }
        }
        return false;
    }
```
比如该方法用于用户密码判断，那就是黑客会使用计时攻击来不断的尝试出密码是多少。
使用统计方法，不断尝试出来下一个字符是多少，因为上述判断字符创相等使用的fail-fast。


# 问题
1. 为什么Redis使用Skip-list实现有序集合？
2. 如何实时地统计业务接口的 99% 响应时间？



