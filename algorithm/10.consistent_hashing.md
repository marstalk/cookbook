https://www.acodersjourney.com/system-design-interview-consistent-hashing/


1. we should be able to distribute incoming request uniformly among the set of n database servers;
2. we should be able to dynamically add/remove database servers;
3. when we add/remove a database servers, we need to move minimal amount of data between database servers;


for simple hashing, there are two drawbacks with this approch: **horizontal scalability** and **non-uniformly distribute data across servers**.

# elastic scaling database server /cache server with minimal data remapped.

# avoiding hot-spots 

# conclusion
1. enable elastic scaling of cluster of database or cache servers
2. faciliate replication and partitioning of data across servers;
3. partitioning of data enables uniform distribution which relieves hot pots.
4. points a-c enables hight availability of the system as a whole.

# reference:
- http://tom-e-white.com/2007/11/consistent-hashing.html
- 

---
1. if we add/remove servers from the set, all our existing **mappings are broken**.
2. this means all existing data needs to be **remapped** and **migrated** to different server.
3. This might be a **herculean**英 /ˌhə:kju'li:ən/(费力的) task because it'll either require a **scheduled system downtime** to update mappings or creating read replicas of the existing system which can service queries during the migration. In other words, a lot of pain and expenditure英 /ɪk'spendɪtʃə/(支出).
4. avoid **data hot-spot** in the cluter
5. We cannot expect **uniform distribution** of data coming in all the time. There may be many more keys whose hashValue maps to server number 3 than any other servers , in which case server number 3 will **become a hotspot for queries**.
6. 